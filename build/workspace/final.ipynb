{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d547959-e63a-410f-b5d1-00287c3e9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from shapely import wkb\n",
    "from shapely import wkb, Point, LineString\n",
    "from pyspark.sql import Row\n",
    "import pyspark.pandas as ps\n",
    "import math\n",
    "\n",
    "ps.set_option('compute.default_index_type', 'distributed')\n",
    "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"spark://spark-master:7077\").config(\"spark.executor.memory\", \"512m\").getOrCreate()\n",
    "\n",
    "#dataframe = spark.read.format(\"jdbc\").options(url=\"jdbc:postgresql://db:5432/datascience?user=postgres&password=mantequilla\", dbtable=\"rutas\",driver=\"org.postgresql.Driver\").load()\n",
    "buses = spark.read.option(\"header\",True).csv(\"./data/buses.csv\")\n",
    "paraderos2 = spark.read.option(\"header\",True).csv(\"./data/paraderos2.csv\")\n",
    "paraderosrutas = spark.read.option(\"header\",True).csv(\"./data/paraderosrutas.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff1bc2-944e-4c6a-8b6d-d1d6f24b8f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce897658-5556-439c-ab0c-5030150a8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def length(s) -> int:\n",
    "    return len(s)\n",
    "def some(item):\n",
    "    punto_bus = wkb.loads(item[\"geom_bus\"], hex=True)\n",
    "    punto_paradero = wkb.loads(item[\"parder_geom\"], hex=True)\n",
    "    distancia = punto_bus.distance(punto_paradero)\n",
    "    temp = item\n",
    "    temp[\"distancia\"] = distancia\n",
    "    return temp\n",
    "def getMin(row):\n",
    "    peq = row.min()\n",
    "    return row.filter(row.distancia == peq) \n",
    "def createData(buses, paraderos2, paraderosrutas):\n",
    "    \n",
    "    busesrutas = paraderosrutas.join(buses, [buses.vendor == paraderosrutas.cod_sinser]).select(paraderosrutas.simt, \n",
    "        buses.bus, buses.fechahora, buses.lat, buses.lng, buses.velocidad, buses.pasajeros, buses.vendor, buses.id, buses.geom.alias(\"geom_bus\"),\n",
    "        paraderosrutas.servicio, paraderosrutas.nombre_par, paraderosrutas.geom.alias(\"parder_geom\"))\n",
    "    \n",
    "    data = busesrutas.join(paraderos2, paraderos2.stop_id == busesrutas.simt, 'inner').select(busesrutas.simt, busesrutas.bus, busesrutas.fechahora, busesrutas.lat, busesrutas.lng, busesrutas.velocidad, busesrutas.pasajeros, busesrutas.vendor, busesrutas.id, busesrutas.geom_bus, busesrutas.servicio, busesrutas.nombre_par, busesrutas.parder_geom, paraderos2.stop_id.alias('parader'), paraderos2.stop_name, paraderos2.stop_lat.alias('parder_lat'), paraderos2.stop_lon.alias('parder_lon'))\n",
    "    \n",
    "    #print(busesrutas.to_pandas_on_spark().spark.coalesce(10).shape, paraderos2.to_pandas_on_spark().spark.coalesce(10).shape, data.to_pandas_on_spark().spark.coalesce(10).shape)\n",
    "    \n",
    "    geom = data.select(data.columns).coalesce(10)\n",
    "    data_pd = geom.to_pandas_on_spark()#.coalesce(3)\n",
    "    data_pd_chunk = data_pd.spark.coalesce(10)\n",
    "    \n",
    "    new_geom = data_pd_chunk.apply(some, axis='columns')\n",
    "    busesparaderos = new_geom.to_spark()\n",
    "    \n",
    "    temp_minimos = busesparaderos.groupBy(['fechahora']).agg(F.min(busesparaderos.distancia).alias(\"md\"))\n",
    "    temp_minimos = busesparaderos.groupBy(['fechahora']).agg(F.min(busesparaderos.distancia).alias(\"md\"))\n",
    "    temp_minimos.printSchema()\n",
    "    minimos = temp_minimos.select(temp_minimos.md,temp_minimos.fechahora.alias(\"fh\"))\n",
    "\n",
    "    resultados = busesparaderos.join(minimos, [busesparaderos.distancia == minimos.md , busesparaderos.fechahora == minimos.fh], 'inner')\n",
    "    \n",
    "    return resultados\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bac479-ddc4-4ea4-8f0f-1595f2f5d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = createData(buses,paraderos2, paraderosrutas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f974bc5-fa89-4dc2-8f44-3be2dcba7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_Punta(data_k,geo,geo_lat,geo_lon,dataframe_buses,n,S):\n",
    "    #HORA PUNTA\n",
    "    Hora_PUNTA = ['2018-06-13 07:00:00+00','2018-06-13 08:59:59+00','2018-06-13 18:00:00+00','2018-06-13 19:59:59+00']\n",
    "    df_sh = data_k\n",
    "    if S == 'S1':\n",
    "        df_sh = data_k[(data_k['fechahora'] >= Hora_PUNTA[0]) & (data_k['fechahora'] <= Hora_PUNTA[1])]\n",
    "    elif S == 'S2':\n",
    "        df_sh = data_k[(data_k['fechahora'] >= Hora_PUNTA[2]) & (data_k['fechahora'] <= Hora_PUNTA[3])]\n",
    "    data_ord = df_sh.sort_values(by=['fechahora'])\n",
    "    data_ord['fechahora'] = pd.to_datetime(data_ord['fechahora'], infer_datetime_format=True)\n",
    "    date_list = data_ord['fechahora'].tolist()\n",
    "    dif_times = []\n",
    "\n",
    "    for k in range(len(date_list)):\n",
    "        if k > 0:\n",
    "            dif_times.append((date_list[k]-date_list[k-1]).total_seconds())\n",
    "\n",
    "    mean = np.mean(dif_times)\n",
    "    dataframe_buses['paradero'].append(n)\n",
    "    dataframe_buses['tiempo_promedio'].append(mean)\n",
    "    dataframe_buses['geo_parader'].append(geo)\n",
    "    dataframe_buses['geo_parader_lat'].append(geo_lat)\n",
    "    dataframe_buses['geo_parader_lon'].append(geo_lon)\n",
    "    dataframe_buses['zona_h'].append('Punta')\n",
    "    dataframe_buses['zona_h_num'].append(1)\n",
    "    dataframe_buses['seccion'].append(S)\n",
    "    if mean < 600:\n",
    "        dataframe_buses['calificacion'].append(2)\n",
    "    elif mean == 600:\n",
    "        dataframe_buses['calificacion'].append(1)\n",
    "    else:\n",
    "        dataframe_buses['calificacion'].append(0)\n",
    "\n",
    "    return dataframe_buses\n",
    "\n",
    "def H_Valle(data_k,geo,geo_lat,geo_lon,dataframe_buses,n,S):\n",
    "    #HORA VALLE\n",
    "    Hora_VALLE = ['2018-06-13 09:00:00+00','2018-06-13 17:59:59+00','2018-06-13 20:00:00+00','2018-06-13 20:44:59+00']\n",
    "    df_sh = data_k\n",
    "    if S == 'S1':\n",
    "        df_sh = data_k[(data_k['fechahora'] >= Hora_VALLE[0]) & (data_k['fechahora'] <= Hora_VALLE[1])]\n",
    "    elif S == 'S2':\n",
    "        df_sh = data_k[(data_k['fechahora'] >= Hora_VALLE[2]) & (data_k['fechahora'] <= Hora_VALLE[3])]\n",
    "    data_ord = df_sh.sort_values(by=['fechahora'])\n",
    "    data_ord['fechahora'] = pd.to_datetime(data_ord['fechahora'], infer_datetime_format=True)\n",
    "    date_list = data_ord['fechahora'].tolist()\n",
    "    dif_times = []\n",
    "\n",
    "    for k in range(len(date_list)):\n",
    "        if k > 0:\n",
    "            dif_times.append((date_list[k]-date_list[k-1]).total_seconds())\n",
    "\n",
    "    mean = np.mean(dif_times)\n",
    "    dataframe_buses['paradero'].append(n)\n",
    "    dataframe_buses['tiempo_promedio'].append(mean)\n",
    "    dataframe_buses['geo_parader'].append(geo)\n",
    "    dataframe_buses['geo_parader_lat'].append(geo_lat)\n",
    "    dataframe_buses['geo_parader_lon'].append(geo_lon)\n",
    "    dataframe_buses['zona_h'].append('Valle')\n",
    "    dataframe_buses['zona_h_num'].append(2)\n",
    "    dataframe_buses['seccion'].append(S)\n",
    "    if mean < 600:\n",
    "        dataframe_buses['calificacion'].append(2)\n",
    "    elif mean == 600:\n",
    "        dataframe_buses['calificacion'].append(1)\n",
    "    else:\n",
    "        dataframe_buses['calificacion'].append(0)\n",
    "\n",
    "    return dataframe_buses\n",
    "def H_Bajo(data_k,geo,geo_lat,geo_lon,dataframe_buses,n,S):\n",
    "    #HORA BAJO\n",
    "    Hora_BAJO = ['2018-06-13 00:00:00+00','2018-06-13 06:59:00+00','2018-06-13 20:45:00+00','2018-06-13 23:59:59+00']\n",
    "    df_sh = data_k\n",
    "    if S == 'S1':\n",
    "        df_sh = data_k[(data_k['fechahora'] >= Hora_BAJO[0]) & (data_k['fechahora'] <= Hora_BAJO[1])]\n",
    "    elif S == 'S2':\n",
    "        df_sh = data_k[(data_k['fechahora'] >= Hora_BAJO[2]) & (data_k['fechahora'] <= Hora_BAJO[3])]\n",
    "    data_ord = df_sh.sort_values(by=['fechahora'])\n",
    "    data_ord['fechahora'] = pd.to_datetime(data_ord['fechahora'], infer_datetime_format=True)\n",
    "    date_list = data_ord['fechahora'].tolist()\n",
    "    dif_times = []\n",
    "\n",
    "    for k in range(len(date_list)):\n",
    "        if k > 0:\n",
    "            dif_times.append((date_list[k]-date_list[k-1]).total_seconds())\n",
    "\n",
    "    mean = np.mean(dif_times)\n",
    "    dataframe_buses['paradero'].append(n)\n",
    "    dataframe_buses['tiempo_promedio'].append(mean)\n",
    "    dataframe_buses['geo_parader'].append(geo)\n",
    "    dataframe_buses['geo_parader_lat'].append(geo_lat)\n",
    "    dataframe_buses['geo_parader_lon'].append(geo_lon)\n",
    "    dataframe_buses['zona_h'].append('Bajo')\n",
    "    dataframe_buses['zona_h_num'].append(3)\n",
    "    dataframe_buses['seccion'].append(S)\n",
    "    if mean < 600:\n",
    "        dataframe_buses['calificacion'].append(2)\n",
    "    elif mean == 600:\n",
    "        dataframe_buses['calificacion'].append(1)\n",
    "    else:\n",
    "        dataframe_buses['calificacion'].append(0)\n",
    "\n",
    "    return dataframe_buses\n",
    "\n",
    "def H_All(data_k,geo,geo_lat,geo_lon,dataframe_buses,n):\n",
    "    data_ord = data_k.sort_values(by=['fechahora'])\n",
    "    data_ord['fechahora'] = pd.to_datetime(data_ord['fechahora'], infer_datetime_format=True)\n",
    "    date_list = data_ord['fechahora'].tolist()\n",
    "    dif_times = []\n",
    "\n",
    "    for k in range(len(date_list)):\n",
    "        if k > 0:\n",
    "            dif_times.append((date_list[k]-date_list[k-1]).total_seconds())\n",
    "\n",
    "    mean = np.mean(dif_times)\n",
    "    dataframe_buses['paradero'].append(n)\n",
    "    dataframe_buses['tiempo_promedio'].append(mean)\n",
    "    dataframe_buses['geo_parader'].append(geo)\n",
    "    dataframe_buses['geo_parader_lat'].append(geo_lat)\n",
    "    dataframe_buses['geo_parader_lon'].append(geo_lon)\n",
    "    if mean < 600:\n",
    "        dataframe_buses['calificacion'].append(2)\n",
    "    elif mean == 600:\n",
    "        dataframe_buses['calificacion'].append(1)\n",
    "    else:\n",
    "        dataframe_buses['calificacion'].append(0)\n",
    "\n",
    "    return dataframe_buses\n",
    "\n",
    "#*************************\n",
    "def getPromRegcBus():#Regularidad\n",
    "    Hour_list_from = ['2018-06-13 00:00:00+00','2018-06-13 01:00:00+00','2018-06-13 02:00:00+00','2018-06-13 03:00:00+00','2018-06-13 04:00:00+00','2018-06-13 05:00:00+00','2018-06-13 06:00:00+00','2018-06-13 07:00:00+00','2018-06-13 08:00:00+00','2018-06-13 09:00:00+00','2018-06-13 10:00:00+00','2018-06-13 11:00:00+00','2018-06-13 12:00:00+00','2018-06-13 13:00:00+00','2018-06-13 14:00:00+00','2018-06-13 15:00:00+00','2018-06-13 16:00:00+00','2018-06-13 18:00:00+00','2018-06-13 19:00:00+00','2018-06-13 20:00:00+00','2018-06-13 21:00:00+00','2018-06-13 22:00:00+00','2018-06-13 23:00:00+00']\n",
    "    Hour_list_to = ['2018-06-13 00:59:59+00','2018-06-13 01:59:59+00','2018-06-13 02:59:59+00','2018-06-13 03:59:59+00','2018-06-13 04:59:59+00','2018-06-13 05:59:59+00','2018-06-13 06:59:59+00','2018-06-13 07:59:59+00','2018-06-13 08:59:59+00','2018-06-13 09:59:59+00','2018-06-13 10:59:59+00','2018-06-13 11:59:59+00','2018-06-13 12:59:59+00','2018-06-13 13:59:59+00','2018-06-13 14:59:59+00','2018-06-13 15:59:59+00','2018-06-13 16:59:59+00','2018-06-13 18:59:59+00','2018-06-13 19:59:59+00','2018-06-13 20:59:59+00','2018-06-13 21:59:59+00','2018-06-13 22:59:59+00','2018-06-13 23:59:59+00']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dataframe_ruta = pd.read_csv(\"./E04I.csv\")\n",
    "    #temp2 = dataframe_ruta.groupby(['parader'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    temp4 = dataframe_ruta.groupby(['bus'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    #print(temp2)\n",
    "    #temp4 = dataframe_ruta.groupby(['parder_geom'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    #list_bus = temp2.index.levels[0]\n",
    "\n",
    "    #temp3 = temp2.loc['PA146']\n",
    "    list_bus = temp4.index.levels[0]\n",
    "    #print(list_bus)\n",
    "    #temp5 = temp4.loc['BJFS-70']\n",
    "    #a = temp2.loc['PA146']['fechahora'].tolist()[0]\n",
    "    \n",
    "    #b = a.sort_values(by=['fechahora'])\n",
    "    #print(temp3)\n",
    "    \n",
    "    #w = temp3.groupby(['bus'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    #temp6 = temp5.sort_values(by=['fechahora'])\n",
    "    #del temp6['parder_geom']\n",
    "    #del temp6['nombre_par']\n",
    "    \n",
    "    #print(temp6)\n",
    "    dataframe_list = list()\n",
    "    for i in list_bus:\n",
    "        x = temp4.loc[i]\n",
    "        a = x.sort_values(by=['fechahora'])\n",
    "        del a['nombre_par']\n",
    "        #del a['parder_geom']\n",
    "        for j in range(23):\n",
    "            #print(j)\n",
    "            df = a[(a['fechahora'] >= Hour_list_from[j]) & (a['fechahora'] <= Hour_list_to[j])]\n",
    "            #if i == 'BJFS-70':\n",
    "                #print(df)\n",
    "            df_g = df.loc[df.groupby('parader')['d'].idxmin()]\n",
    "            #if i == 'BJFS-70':\n",
    "                #print(df_g)\n",
    "            dataframe_list.append(df_g)\n",
    "\n",
    "\n",
    "    dataframe_buses = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[]}\n",
    "    # ESTAN ASI PORQUE NO SE Q WEA CON LOS PUNTEROS\n",
    "    dataframe_buses_p1 = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[],'zona_h':[],'zona_h_num':[],'seccion':[]}\n",
    "    dataframe_buses_p2 = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[],'zona_h':[],'zona_h_num':[],'seccion':[]}\n",
    "    dataframe_buses_v1 = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[],'zona_h':[],'zona_h_num':[],'seccion':[]}\n",
    "    dataframe_buses_v2 = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[],'zona_h':[],'zona_h_num':[],'seccion':[]}\n",
    "    dataframe_buses_b1 = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[],'zona_h':[],'zona_h_num':[],'seccion':[]}\n",
    "    dataframe_buses_b2 = {'paradero':[],'tiempo_promedio':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[],'zona_h':[],'zona_h_num':[],'seccion':[]}\n",
    "\n",
    "\n",
    "    dataf = pd.concat(dataframe_list)\n",
    "    \n",
    "    data_gp = dataf.groupby(['parader'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    #print(data_gp)\n",
    "    list_parader = data_gp.index.levels[0]\n",
    "    #mean_list = []\n",
    "    for n in list_parader:\n",
    "        data_k = data_gp.loc[n]\n",
    "        geo = data_k['parder_geom'].iat[0]\n",
    "        geo_lat = data_k['parder_lat'].iat[0]\n",
    "        geo_lon = data_k['parder_lon'].iat[0]\n",
    "        \n",
    "        H_Punta(data_k,geo,geo_lat,geo_lon,dataframe_buses_p1,n,'S1')\n",
    "        H_Punta(data_k,geo,geo_lat,geo_lon,dataframe_buses_p2,n,'S2')\n",
    "        H_Valle(data_k,geo,geo_lat,geo_lon,dataframe_buses_v1,n,'S1')\n",
    "        H_Valle(data_k,geo,geo_lat,geo_lon,dataframe_buses_v2,n,'S2')\n",
    "        H_Bajo(data_k,geo,geo_lat,geo_lon,dataframe_buses_b1,n,'S1')\n",
    "        H_Bajo(data_k,geo,geo_lat,geo_lon,dataframe_buses_b2,n,'S2')\n",
    "        H_All(data_k,geo,geo_lat,geo_lon,dataframe_buses,n)\n",
    "\n",
    "   \n",
    "        \n",
    "    dataframe_total_busparadero_punta1 = pd.DataFrame(dataframe_buses_p1)\n",
    "    dataframe_total_busparadero_punta2 = pd.DataFrame(dataframe_buses_p2)\n",
    "    dataframe_total_busparadero_valle1 = pd.DataFrame(dataframe_buses_v1)\n",
    "    dataframe_total_busparadero_valle2 = pd.DataFrame(dataframe_buses_v2)\n",
    "    dataframe_total_busparadero_bajo1 = pd.DataFrame(dataframe_buses_b1)\n",
    "    dataframe_total_busparadero_bajo2 = pd.DataFrame(dataframe_buses_b2)\n",
    "    dataframe_total_busparadero = pd.DataFrame(dataframe_buses)\n",
    "    #print(dataframe_total_busparadero_punta1,dataframe_total_busparadero_punta2,dataframe_total_busparadero_valle1,dataframe_total_busparadero_valle2,dataframe_total_busparadero_bajo1,dataframe_total_busparadero_bajo2,dataframe_total_busparadero)\n",
    "\n",
    "    dataframe_total_busparadero_punta1.to_csv('E04I_PUNTA1.csv')\n",
    "    dataframe_total_busparadero_punta2.to_csv('E04I_PUNTA2.csv')\n",
    "    dataframe_total_busparadero_valle1.to_csv('E04I_VALLE1.csv')\n",
    "    dataframe_total_busparadero_valle2.to_csv('E04I_VALLE2.csv')\n",
    "    dataframe_total_busparadero_bajo1.to_csv('E04I_BAJO1.csv')\n",
    "    dataframe_total_busparadero_bajo2.to_csv('E04I_BAJO2.csv')\n",
    "    dataframe_total_busparadero.to_csv('E04I_ALL.csv')\n",
    "\n",
    "def get_Bus_Cant_Prom_Por_Paredero(source):#Frecuenica\n",
    "    Hour_list_from = ['2018-06-13 00:00:00+00','2018-06-13 01:00:00+00','2018-06-13 02:00:00+00','2018-06-13 03:00:00+00','2018-06-13 04:00:00+00','2018-06-13 05:00:00+00','2018-06-13 06:00:00+00','2018-06-13 07:00:00+00','2018-06-13 08:00:00+00','2018-06-13 09:00:00+00','2018-06-13 10:00:00+00','2018-06-13 11:00:00+00','2018-06-13 12:00:00+00','2018-06-13 13:00:00+00','2018-06-13 14:00:00+00','2018-06-13 15:00:00+00','2018-06-13 16:00:00+00','2018-06-13 18:00:00+00','2018-06-13 19:00:00+00','2018-06-13 20:00:00+00','2018-06-13 21:00:00+00','2018-06-13 22:00:00+00','2018-06-13 23:00:00+00']\n",
    "    Hour_list_to = ['2018-06-13 00:59:59+00','2018-06-13 01:59:59+00','2018-06-13 02:59:59+00','2018-06-13 03:59:59+00','2018-06-13 04:59:59+00','2018-06-13 05:59:59+00','2018-06-13 06:59:59+00','2018-06-13 07:59:59+00','2018-06-13 08:59:59+00','2018-06-13 09:59:59+00','2018-06-13 10:59:59+00','2018-06-13 11:59:59+00','2018-06-13 12:59:59+00','2018-06-13 13:59:59+00','2018-06-13 14:59:59+00','2018-06-13 15:59:59+00','2018-06-13 16:59:59+00','2018-06-13 18:59:59+00','2018-06-13 19:59:59+00','2018-06-13 20:59:59+00','2018-06-13 21:59:59+00','2018-06-13 22:59:59+00','2018-06-13 23:59:59+00']\n",
    "    dataframe_ruta = source#.toPandas()\n",
    "    \n",
    "    #temp2 = dataframe_ruta.groupby(['parader'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    temp2 = dataframe_ruta.groupBy(['parader']).apply(lambda x: x)\n",
    "    return \n",
    "    #temp4 = dataframe_ruta.groupby(['parder_geom'], group_keys=True, as_index=True).apply(lambda x: x)\n",
    "    list_paredors = temp2.index.levels[0]\n",
    "    #temp3 = temp2.loc['PA146']\n",
    "    #a = temp2.loc['PA146']['fechahora'].tolist()[0]\n",
    "\n",
    "    dataframe_buses = {'paradero':[],'promedio_bus_hora':[],'geo_parader':[],'geo_parader_lat':[],'geo_parader_lon':[],'calificacion':[]}\n",
    "    #print(len(Hour_list_from))\n",
    "    #print(len(Hour_list_to))\n",
    "\n",
    "    for i in list_paredors: \n",
    "        x = temp2.loc[i]\n",
    "        List_total_buses = list()\n",
    "        geo = x['parder_geom'].iat[0]\n",
    "        geo_lat = x['parder_lat'].iat[0]\n",
    "        geo_lon = x['parder_lon'].iat[0]\n",
    "        #paradero_list = list()\n",
    "        #print(geo)\n",
    "        for j in range(23):\n",
    "            #print(j)\n",
    "            df = x[(x['fechahora'] >= Hour_list_from[j]) & (x['fechahora'] <= Hour_list_to[j])]\n",
    "            List_total_buses.append(df['bus'].nunique())\n",
    "            #Lista_interval.append(Hour_list_from[j]+' to '+Hour_list_to[j])\n",
    "        mean = (sum(List_total_buses) / 24)\n",
    "        dataframe_buses['paradero'].append(i)\n",
    "        dataframe_buses['promedio_bus_hora'].append(mean)\n",
    "        dataframe_buses['geo_parader'].append(geo)\n",
    "        dataframe_buses['geo_parader_lat'].append(geo_lat)\n",
    "        dataframe_buses['geo_parader_lon'].append(geo_lon)\n",
    "        if mean < 5:\n",
    "            dataframe_buses['calificacion'].append(0)\n",
    "        elif mean > 6:\n",
    "            dataframe_buses['calificacion'].append(1)\n",
    "        else:\n",
    "            dataframe_buses['calificacion'].append(2)\n",
    "\n",
    "\n",
    "        \n",
    "        #dataframe_buses['rango_hora'] += Lista_interval\n",
    "\n",
    "\n",
    "    dataframe_total_busparadero = pd.DataFrame(dataframe_buses)\n",
    "\n",
    "#print(resultados.to_pandas_on_spark().shape)\n",
    "#get_Bus_Cant_Prom_Por_Paredero(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4ccf0-6b40-400d-9df2-476c1f9b31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(group):\n",
    "    name = group.service\n",
    "    get_Bus_Cant_Prom_Por_Paredero(name)\n",
    "    getPromRegcBus(name)\n",
    "    return group\n",
    "todo_pandas = todo.to_pandas_on_spark().spark.coalesce(10)\n",
    "todo_pandas.groupby('servicio').apply(processing, as_index=False, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0ceb6-6c59-4822-91cd-cdd1a24a7e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55566a-0ba4-4314-8fe3-dc1a94d2ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2651c-d2b0-4d43-9105-97b620e7a1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
